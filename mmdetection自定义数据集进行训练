

该日志转自CSDN博客 https://blog.csdn.net/xiangxianghehe/article/details/89812058

根据网友评论及电脑配置和路径的实际情况进行了修改

__本日志以清华-奔驰戴姆勒联合实验室的benchmark数据集TsinghuaDaimler Dataset为例，具体演示其中的具体application__

```text
这里提供一个具体详细的mmdetection源码解读和实践教程，从虚拟环境安装到自定义数据集实践（模型训练和测试）都有详细的流程介绍和注意事项解释 
http://www.pythonheidong.com/blog/article/53032/
```

[__快速参考上述链接__](http://www.pythonheidong.com/blog/article/53032/)

### 数据集格式转换

*mmdetection对coco数据优先支持。所以在开始之前建议把自己数据修改为标准的coco格式，各种类型数据转coco格式脚本见：[__转换工具__](https://github.com/spytensor/prepare_detection_dataset) （Github）

链接URL：[__https://github.com/spytensor/prepare_detection_dataset__](https://github.com/spytensor/prepare_detection_dataset)

系列一主要介绍如何在常见的几种数据格式之间进行转换，以及万能中介`csv`格式的使用，这里列出以下几个：

- csv to coco

- csv to voc

- labelme to coco

- labelme to voc

- csv to json



### mmdetection训练自己数据

### 第一步当然是定义数据种类，需要修改的地方在mmdet\datasets

在这个目录下新建一个文件，例如:my_data.py (cyclist.py)，然后把coco.py的内容复制过来，修改class类名为Mydataset (Cyclist) 最后把CLASSES的那个tuple改为自己数据集对应的种类tuple (按照Tsinghua的目标分类方式)即可，例如：

```python
CLASSES = ('1', '2', '3', '4', '5', '6', '7', '8', '9', '10',
           '11', '12', '13', '14', '15', '16', '17', '18', '19', '20')
```

表明你的数据集有21类（包含背景），命名是’1’-‘20’，还有一类背景。

```python
CLASSES = (‘cyclist',) 
```

表明你的数据集有2类（包含背景），命名是’cyclist，’，还有一类背景。

![](https://tcs.teambition.net/storage/111s6b0a8e341d926906f29418a72087f41a?Signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJBcHBJRCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9hcHBJZCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9vcmdhbml6YXRpb25JZCI6IiIsImV4cCI6MTU5MDA2MTAyOSwiaWF0IjoxNTg5NDU2MjI5LCJyZXNvdXJjZSI6Ii9zdG9yYWdlLzExMXM2YjBhOGUzNDFkOTI2OTA2ZjI5NDE4YTcyMDg3ZjQxYSJ9.Aos74iEz8L9wggUJIpjmjmSTBQSo9hZOzlClHERvFDA&download=cylcist.png "")

### 接着在mmdet\datasets\__init__.py引入你自定义的数据集

在这个py文件中开头加入

`from ``.my_data.py ``import MyDataset`

my correct example:

```text
from .cyclist import Cyclist
```

然后在__all__列表中加入你的MyDataset ('Cyclist')

```python
__all__ = [
    'CustomDataset', 'XMLDataset', 'CocoDataset', 'VOCDataset',
    'CityscapesDataset', 'GroupSampler', 'DistributedGroupSampler',
    'build_dataloader', 'ConcatDataset', 'RepeatDataset', 'WIDERFaceDataset','DATASETS', 'build_dataset', 'Cyclist'
]
```

### 然后在mmdet\core\evaluation\class_names.py中加入你刚才的数据集类别

在开头加入

```python
def cyclist_classes():
    return ['cyclist', 'pedestrian', 'motorcyclist',  'tricyclist', 'wheelchairuser', 'mopedrider'
    ]
```

然后在dataset_aliases字典中加入：

`'mydata':['mydata']`

My correct example:

```python
dataset_aliases = {
    'cyclist':['cyclist'], 'voc': ['voc', 'pascal_voc', 'voc07', 'voc12'],
    'imagenet_det': ['det', 'imagenet_det', 'ilsvrc_det'],
    'imagenet_vid': ['vid', 'imagenet_vid', 'ilsvrc_vid'],
    'coco': ['coco', 'mscoco', 'ms_coco'],
    'wider_face': ['WIDERFaceDataset', 'wider_face', 'WDIERFace'],
    'cityscapes': ['cityscapes']
}
```

最后在mmdet\core\evaluation\__init__.py开头引入你自定义的数据集

```python
from .class_names import cyclist_classes
```

在__all__列表中加入你的mydata_classes

```python
__all__ = ['cyclist_classes', 'voc_classes', 'imagenet_det_classes', 'imagenet_vid_classes','coco_classes', 'dataset_aliases', 'get_classes', 'coco_eval','fast_eval_recall', 'results2json', 'DistEvalHook', 'DistEvalmAPHook','CocoDistEvalRecallHook', 'CocoDistEvalmAPHook', 'average_precision','eval_map', 'print_map_summary', 'eval_recalls', 'print_recall_summary', 'plot_num_recall', 'plot_iou_recall'
]
```

### 在你训练的config文件中引入自己数据路径即可 (以mmdetection的Faster R-CNN Resnet50为例)

在config文件中把dataset_type改为mydata (Cyclist)，然后把data_root改成你coco格式自定义数据集的根目录即可。

```python
mmdetection
-mmdet
-configs
-data
 --coco
   ---annotations
   ---train
   ---val
   ---test

#
TsinghuaDaimlerDataset
-annotations
-LabelData
-LeftImg8bit
-TsinghuaDaimlerScript
```

![](https://tcs.teambition.net/storage/111pf8eb696b6fffb6eb5896dcc278942f7d?Signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJBcHBJRCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9hcHBJZCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9vcmdhbml6YXRpb25JZCI6IiIsImV4cCI6MTU5MDA2MTAyOSwiaWF0IjoxNTg5NDU2MjI5LCJyZXNvdXJjZSI6Ii9zdG9yYWdlLzExMXBmOGViNjk2YjZmZmZiNmViNTg5NmRjYzI3ODk0MmY3ZCJ9.guAbNgV-ci8346gtkYaSaMkTbNqDF-JW96UDdsPw_vU&download=Screenshot%20from%202020-01-09%2011-27-37.png "")

```python
#faster_rcnn_r50_fpn_1x.py
# dataset settings
dataset_type = 'Cyclist'
# data_root = '/home/cloud/git_repo/xiaobai/research/mmdetection/data/Cyclist'
data_root = '/home/cloud/git_repo/xiaobai/research/TsinghuaDaimlerDatasets/'

#还有一处需要修改 博客里面没有具体提到 在后面的annotations路径设置这里
#根据你数据集路径的实际路径为主 我单独创建了一个annotations的文件夹 来放置三个json文件 这三个文件是benchmark数据集自带的 包含了Labeldata这个文件夹所有的json数据 币labeldata去一一对应路径方便简洁许多

data = dict(
    imgs_per_gpu=2,
    workers_per_gpu=2,
    train=dict(
        type=dataset_type,
        ann_file=data_root + '/annotations/train.json',
        img_prefix=data_root + 'LeftImg8bit/train/tsinghuaDaimlerDataset/',
        pipeline=train_pipeline),
    val=dict(
        type=dataset_type,
        ann_file=data_root + '/annotations/val.json',
        img_prefix=data_root + 'LeftImg8bit/valid/tsinghuaDaimlerDataset/',
        pipeline=test_pipeline),
    test=dict(
        type=dataset_type,
        ann_file=data_root + '/annotations/test.json',
        img_prefix=data_root + 'LeftImg8bit/test/tsinghuaDaimlerDataset/',
        pipeline=test_pipeline))

#注意检查work_dir的保存路径 确保训练好的模型epoch有妥善保存
```

### 在`train.py`中调用你的模型参数 

```python
def parse_args():
    parser = argparse.ArgumentParser(description='Train a detector')
    # parser.add_argument('--config', help='train config file path')
    parser.add_argument('--config', default='/home/cloud/git_repo/xiaobai/research/mmdetection/configs/faster_rcnn_r50_fpn_1x.py', help='train config file path')
```

```python
total_epochs = 20 # 训练最大的epoch数
dist_params = dict(backend='nccl') # 分布式参数
log_level = 'INFO' # 输出信息的完整度级别
work_dir = './work_dirs/libra_faster_rcnn_x101_64x4d_fpn_1x' # log文件和模型文件存储路径
load_from = None # 加载模型的路径，None表示从预训练模型加载
resume_from = None # 恢复训练模型的路径，None表示不进行训练模型的恢复
workflow = [('train', 1)] 
# ======================================================
# 训练与验证策略，[('train', 1)]表示只训练，不验证；
# [('train', 2), ('val', 1)] 表示2个epoch训练，1个epoch验证
# ======================================================
```

原文链接：https://blog.csdn.net/DD_PP_JJ/article/details/103058313

原文链接：https://blog.csdn.net/xiangxianghehe/article/details/89812058

![](https://tcs.teambition.net/storage/111p9bf49787a3e455c7a2378f145e2af547?Signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJBcHBJRCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9hcHBJZCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9vcmdhbml6YXRpb25JZCI6IiIsImV4cCI6MTU5MDA2MTAyOSwiaWF0IjoxNTg5NDU2MjI5LCJyZXNvdXJjZSI6Ii9zdG9yYWdlLzExMXA5YmY0OTc4N2EzZTQ1NWM3YTIzNzhmMTQ1ZTJhZjU0NyJ9.mkV77gYNffrbCWUPKoebagtKdA2DZDn3TPG1ZNVofSk&download=yesss.png "")

*记得使用watch -n 0.1 nvidia-smi 监视查看你的GPU使用情况

*电脑本地内存有限 可以选择将epoch存储在移动硬盘内（避免崩溃错误）

### 训练epoch数据可视化

`It's a very simple version for visualizing the training result produced by mmdetection`

6.1 下载mmdetection_visualize的插件包

```python
#The program supports drawing six training result and the most important evaluation tool:PR curve(only for VOC now)
#loss_rpn_bbox
#loss_rpn_cls
#loss_bbox
#loss_cls
#loss
#acc
#PR_curve
#F-measure
git clone https://github.com/Stephenfang51/mmdetection_visualize
#There will be total 5 files(json directory, output directory, visualize.py, mean_ap_visualize.py, voc_eval_visualize.py)

```

[__https://python.ctolib.com/Stephenfang51-mmdetection_visualize.html__](https://python.ctolib.com/Stephenfang51-mmdetection_visualize.html) 原文地址

6.2 在mmdetection文件夹里进行两个文件路径移动

-  put `voc_eval_visualize.py` under `/mmdetection/tools/` 

-  put `mean_ap_visualize.py` under `mmdetection/mmdet/core/evaluation/` 



6.3 如何使用

**six training result**

1. After training finished, you will have **work_dir** directory in your mmdetection directory

1. take the latest json file and put into json directory in mmditection_visualize directory

1. command `python visualize.py json/xxxxxxxlog.json` in terminal

1. check the output directory, Done !

```python
#example
python visualize.py 20200108_152947.log.json
```

**PR curve and F-measure**

1. make sure `voc_eval_visualize.py` and `mean_ap_visualize.py` settled down

1. command as usual like `python tools/voc_eval_visualize.py {your pkl file} {your network configs file}`    

    1. example `python tools/voc_eval_visualize.py result.pkl ./configs/faster_rcnn_r101_fpn_1x.py`

1. check the /mmdetection main directory, you will see the **PR_curve_each_class.png** there， Done !



**mmdetection analyze_logs.py **

You can refer to mmdetection/gettingstarted.md for detailed information and instructions

```python
#example
 python /home/cloud/git_repo/xiaobai/research/mmdetection/tools/analyze_logs.py plot_curve /home/cloud/git_repo/xiaobai/research/mmdetection/work_dirs/faster_rcnn_r50_fpn_1x/20200108_152947.log.json --keys loss_cls loss_bbox loss --legend loss_cls loss_bbox loss
```



### 测试数据test.py

 【COCO】COCO数据集较为简单：在终端Terminal执行一条命令

```python
#sample
python tools/test.py configs/faster_rcnn_r50_fpn_1x.py work_dirs/epoch_80.pth --out ./result/result_100.pkl --eval bbox 

#example
python tools/test.py configs/faster_rcnn_r50_fpn_1x.py work_dirs/faster_rcnn_r50_fpn_1x/latest.pth --out ./result/result_100.pkl --eval bbox 
#具体的区别就是我增加了路径 根据个人路径情况不同进行微调
```

【VOC】由于test.py文件中只对coco数据集进行eval，所以先用test.py生成pkl文件，再用eval_voc.py进行计算map

`python tools/test.py configs/RetinaNet.py work_dirs/latest.pth --out=eval/result.pkl`

使用pkl文件计算机每个类的ap

`python tools/voc_eval.py eval/result.pkl configs/RetinaNet.py`

**tools/test.py负责对训练好的模型进行测试评估**

**test.py的使用说明**

1. 输出到文件在数据集上对训练好的模型进行测试，把模型的输出保存到文件：

```python
python3 tools/test.py <CONFIG_FILE> <CHECKPOINT_FILE> --gpus <GPU_NUM> --out <OUT_FILE>
```

1. 评估bbox等预测指标把模型输出保存到results.pkl并评估bbox和segm的测试结果：

```python
python3 tools/test.py configs/mask_rcnn_r50_fpn_1x.py <CHECKPOINT_FILE> --gpus 8 --out results.pkl --eval bbox segm
```

1. 可视化预测结果如果支持X Server，可以显示图形界面，则可以通过–show选项对测试图片进行显示输出：

```python
python3 tools/test.py <CONFIG_FILE> <CHECKPOINT_FILE> --show
=================================================================
#example
python3 /home/cloud/git_repo/xiaobai/research/mmdetection/tools/test.py /home/cloud/git_repo/xiaobai/research/mmdetection/configs/faster_rcnn_r50_fpn_1x.py /home/cloud/git_repo/xiaobai/research/mmdetection/work_dirs/faster_rcnn_r50_fpn_1x/latest.pth --show
```

Cyclist example :

![](https://tcs.teambition.net/storage/111p0f3d894cc882bc8c5ad66713eee82416?Signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJBcHBJRCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9hcHBJZCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9vcmdhbml6YXRpb25JZCI6IiIsImV4cCI6MTU5MDA2MTAyOSwiaWF0IjoxNTg5NDU2MjI5LCJyZXNvdXJjZSI6Ii9zdG9yYWdlLzExMXAwZjNkODk0Y2M4ODJiYzhjNWFkNjY3MTNlZWU4MjQxNiJ9.WJDTW9HGcykySfLDG3ZcephsHkhDaUX5LZ17IDSxNN0&download=test-%20-%20-show.png "")

tools/test.py源码具体解析见源代码处

![](https://tcs.teambition.net/storage/111p2e357fc06bf8c191991135c15e371d98?Signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJBcHBJRCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9hcHBJZCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9vcmdhbml6YXRpb25JZCI6IiIsImV4cCI6MTU5MDA2MTAyOSwiaWF0IjoxNTg5NDU2MjI5LCJyZXNvdXJjZSI6Ii9zdG9yYWdlLzExMXAyZTM1N2ZjMDZiZjhjMTkxOTkxMTM1YzE1ZTM3MWQ5OCJ9.fNy7endt2zh2u4wEkYbOGq97CEPiXJI9Y4eNV8kL1j4&download=%3F%3F%3F%3F.png "")



![](https://tcs.teambition.net/storage/111p6f953fc3bea2e3450d5d99e304a0073f?Signature=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJBcHBJRCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9hcHBJZCI6IjU5Mzc3MGZmODM5NjMyMDAyZTAzNThmMSIsIl9vcmdhbml6YXRpb25JZCI6IiIsImV4cCI6MTU5MDA2MTAyOSwiaWF0IjoxNTg5NDU2MjI5LCJyZXNvdXJjZSI6Ii9zdG9yYWdlLzExMXA2Zjk1M2ZjM2JlYTJlMzQ1MGQ1ZDk5ZTMwNGEwMDczZiJ9.igdES0RJDw_S4PgdGUHqF0dcLTU69eL6ZqtifRgJ5EQ&download=%3F%3F%3F%3F%3F.png "")

__**COCO数据集**__

1.

```python
CUDA_VISIBLE_DEVICES=5 python tools/test.py configs/faster_rcnn_r50_fpn_1x.py work_dirs/faster_rcnn_r50_fpn_1x/latest.pth --out work_dirs/res_cyc.pkl --eval bbox

python tools/test.py /home/bbd/PycharmProjects/xiaobai/mmdetection/configs/empirical_attention/faster_rcnn_r50_fpn_attention_0010_1x.py /home/bbd/PycharmProjects/xiaobai/mmdetection/tools/work_dirs/faster_rcnn_r50_fpn_attention_0010_1x/latest.pth --out work_dirs/res_cyc1.pkl --eval bbox

```

issue 1.1：

```python
writing results to /home/bbd/PycharmProjects/xiaobai/mmdetection/tools/work_dirs/res_cyc1.pkl
Starting evaluate bbox
Loading and preparing results...
DONE (t=0.01s)
creating index...
index created!
Traceback (most recent call last):
  File "/home/bbd/anaconda3/envs/open-mmlab/lib/python3.7/site-packages/numpy/core/function_base.py", line 117, in linspace
    num = operator.index(num)
TypeError: 'numpy.float64' object cannot be interpreted as an integer
```

这里是由于numpy>1.18而导致的 具体解决办法为：

```python
not use numpy 1.18, use numpy version < 1.18
###modify coco evaluation code
#cocoeval.py line 507, line508 
np.round(0.95 - .5) / .05 + 1 
###to↓####
int(np.round(0.95 - .5) / .05 + 1)
```

2.

```python
CUDA_VISIBLE_DEVICES=5 python tools/coco_eval.py /home/cloud/git_repo/xiaobai/research/mmdetection/work_dirs/res_cyc.pkl.bbox.json --ann /home/cloud/git_repo/xiaobai/research/TsinghuaDaimlerDatasets/annotations/test.json --classwise

```

issue 1：

```python
Traceback (most recent call last):
  File "tools/coco_eval.py", line 30, in <module>
    main()
  File "tools/coco_eval.py", line 26, in main
    coco_eval(args.result, args.types, args.ann, args.max_dets, args.classwise)
  File "/home/bbd/PycharmProjects/xiaobai/mmdetection/mmdet/core/evaluation/coco_utils.py", line 70, in coco_eval
    ('{}'.format(nm['name']),
KeyError: 'name'
```

解决办法为：

```python
                results_per_category.append(
                    ('{}'.format(nm['names']),###name改为names###
                     '{:0.3f}'.format(float(ap * 100))))
```

__**VOC数据集**__

首先产生pkl

python test.py configs/faster_rcnn_r50_fpn_1x_voc0712.py work_dirs/faster_rcnn_r50_fpn_1x_voc0712/latest.pth --gpus=1 --out=eval/result.pkl



计算map

python voc_eval.py eval/result.pkl configs/faster_rcnn_r50_fpn_1x_voc0712.py

